# main.py

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator

def create_cnn_model():
    # Táº¡o mÃ´ hÃ¬nh CNN vá»›i cáº£i tiáº¿n
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),  # Dropout Ä‘á»ƒ trÃ¡nh overfitting
        layers.Dense(10, activation='softmax')  # Lá»›p output vá»›i 10 lá»›p cho 10 loáº¡i trong CIFAR-10
    ])
    
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    
    return model

def main():
    # Táº£i dá»¯ liá»‡u CIFAR-10
    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()

    # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
    train_images, test_images = train_images / 255.0, test_images / 255.0  # Chuáº©n hÃ³a áº£nh
    train_labels = to_categorical(train_labels, 10)  # One-hot encoding cho nhÃ£n
    test_labels = to_categorical(test_labels, 10)

    # Sá»­ dá»¥ng Data Augmentation Ä‘á»ƒ tÄƒng cÆ°á»ng dá»¯ liá»‡u huáº¥n luyá»‡n
    datagen = ImageDataGenerator(
        rotation_range=20,        # Xoay ngáº«u nhiÃªn áº£nh
        width_shift_range=0.2,    # Dá»‹ch chuyá»ƒn theo chiá»u ngang
        height_shift_range=0.2,   # Dá»‹ch chuyá»ƒn theo chiá»u dá»c
        shear_range=0.2,          # Biáº¿n dáº¡ng shear
        zoom_range=0.2,           # Thu phÃ³ng áº£nh
        horizontal_flip=True,     # Láº­t áº£nh theo chiá»u ngang
        fill_mode='nearest'       # Äiá»n cÃ¡c vÃ¹ng trá»‘ng
    )
    
    # Fit dá»¯ liá»‡u vÃ o ImageDataGenerator
    datagen.fit(train_images)

    # Táº¡o mÃ´ hÃ¬nh CNN
    model = create_cnn_model()

    # ğŸ‘‰ In ra sá»‘ lÆ°á»£ng tham sá»‘ cá»§a mÃ´ hÃ¬nh
    print("\nğŸ§  ThÃ´ng tin mÃ´ hÃ¬nh:")
    model.summary()
    total_params = model.count_params()
    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])
    non_trainable_params = total_params - trainable_params
    print(f"\nğŸ“Š Tá»•ng tham sá»‘: {total_params:,}")
    print(f"ğŸ“ˆ Tham sá»‘ huáº¥n luyá»‡n Ä‘Æ°á»£c: {trainable_params:,}")
    print(f"ğŸ“‰ Tham sá»‘ khÃ´ng huáº¥n luyá»‡n Ä‘Æ°á»£c: {non_trainable_params:,}")

    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
    print("\nğŸš€ Báº¯t Ä‘áº§u huáº¥n luyá»‡n mÃ´ hÃ¬nh...")

    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i Data Augmentation
    model.fit(datagen.flow(train_images, train_labels, batch_size=64),
              epochs=30,
              validation_data=(test_images, test_labels),
              steps_per_epoch=len(train_images) // 64)

    # ğŸ‘‰ ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test
    print("\nğŸ“‹ ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p kiá»ƒm tra:")
    loss, accuracy = model.evaluate(test_images, test_labels, verbose=2)
    print(f"âœ… Äá»™ chÃ­nh xÃ¡c: {accuracy * 100:.2f}%")
    print(f"âŒ Äá»™ máº¥t mÃ¡t (loss): {loss:.4f}")
    
    # LÆ°u mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    model.save('cnn_cifar10_model.h5')
    print("MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u thÃ nh cÃ´ng!")

if __name__ == "__main__":
    main()